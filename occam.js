// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
import {indentation, newlines} from "./tokens"
const spec_Name = {__proto__:null,"~":40, BITNOT:40, NOT:40, SIZE:40, "+":42, "*":42, "/":42, "\\":42, REM:42, PLUS:42, TIMES:42, "/\\":42, "\\/":42, "><":42, BITAND:42, BITOR:42, AND:42, OR:42, "=":42, "<>":42, "<":42, ">":42, ">=":42, "<=":42, AFTER:42, "-":44, MINUS:44, SKIP:50, STOP:52, SEQ:54}
export const parser = LRParser.deserialize({
  version: 14,
  states: "$hOQOSOOO`OSO'#CcOOOP'#Ce'#CeOOOP'#Cf'#CfOOOQ'#Ch'#ChOkOQO'#CgOOOP'#C^'#C^QOOOOOOpOSO'#CdOxOSO,58yO!WOPO,59ROxOSO,59OO!]OSO,58|O!bOTO'#CnO!|OSO'#CnOOOP'#Co'#CoOOOP1G.e1G.eOQOSO1G.mOOOP1G.j1G.jOOOP1G.h1G.hO!|OSO,59YOOOP,59Y,59YO#UOTO'#CxO#gOPO7+$XOOOP1G.t1G.tOOOP,59d,59dOOOP<<Gs<<Gs",
  stateData: "#l~OSPOiQOjROkSO~OaXOgVXhVX~O`YO~Og[OhZO~OS_OT_Od^Of^O~O^aO~OScO~OedOfeO]bXSbX_bXibXjbXkbX~OS_OT_O~OSPOiQOjROkSO_lX~O_jO~O",
  goto: "!lmPPnuPPuzuuuu!PPPPPP!U![PPPPPPPP!fQVOTfafVUOafVWOafVTOafQ`XRbZS]XZQe^RhdQgaRif",
  nodeNames: "âš  Program Process Assignment Name Integer Input Channel Output Skip Stop Sequence Seq",
  maxTerm: 28,
  skippedNodes: [0],
  repeatNodeCount: 0,
  tokenData: "!_~RUqre!Q![j![!]r!a!b}!c!}!S#T#o!S~jOh~~oPT~!Q![j~uP!_!`x~}Oa~~!SOg~~!XQS~!c!}!S#T#o!S",
  tokenizers: [indentation, newlines, 0],
  topRules: {"Program":[0,1]},
  specialized: [{term: 4, get: value => spec_Name[value] || -1}],
  tokenPrec: 0
})
